{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system('pip install bs4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "import time\n",
    "import  pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from tqdm import tqdm\n",
    "from fake_useragent import UserAgent\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chmod(os.path.join(os.getcwd(), 'chromedriver.exe'), int('0755'))\n",
    "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/My Drive/Scraper'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a request using `requests` to grab the content of the site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_AGENT = { \n",
    "'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36', \n",
    "'Accept' : 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \n",
    "'Accept-Language' : 'en-US,en;q=0.5',\n",
    "'Accept-Encoding' : 'gzip', \n",
    "'DNT' : '1', # Do Not Track Request Header \n",
    "'Connection' : 'close'\n",
    "}\n",
    "response = requests.get(URL, headers=USER_AGENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!--\\n        To discuss automated access to Amazon data please contact api-services-support@amazon.com.\\n        For information about migrating to our APIs refer to our Marketplace APIs at https://developer.amazonservices.com/ref=rm_5_sv, or our Product Advertising API at https://affiliate-program.amazon.com/gp/advertising/api/detail/main.html/ref=rm_5_ac for advertising use cases.\\n-->\\n<!doctype html>\\n<html>\\n<head>\\n  <meta charset=\"utf-8\">\\n  <meta http-equiv=\"x-ua-compatible\" content=\"ie=edge\">\\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\\n  <title>Sorry! Something went wrong!</title>\\n  <style>\\n  html, body {\\n    padding: 0;\\n    margin: 0\\n  }\\n\\n  img {\\n    border: 0\\n  }\\n\\n  #a {\\n    background: #232f3e;\\n    padding: 11px 11px 11px 192px\\n  }\\n\\n  #b {\\n    position: absolute;\\n    left: 22px;\\n    top: 12px\\n  }\\n\\n  #c {\\n    position: relative;\\n    max-width: 800px;\\n    padding: 0 40px 0 0\\n  }\\n\\n  #e, #f {\\n    height: 35px;\\n    border: 0;\\n    font-size: '"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# container = soup.find_all('div', attrs={'class': 'sg-col-inner'}) #pg2\n",
    "container = soup.find_all('span', {'class': 'nav-line-1'}) #pg2\n",
    "\n",
    "# container = soup.find_all('div', attrs={'class': 'a-section a-spacing-medium'}) #pg2\n",
    "\n",
    "# container = soup.find_all('div', attrs={'class': 's-item-container'}) #pg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = container[2]\n",
    "# Item_name\n",
    "print(first.find_all('span', attrs={'class': 'a-size-base-plus a-color-base a-text-normal'})[0].text)\n",
    "# item_img_link\n",
    "print(first.find_all('img', attrs={'class': 's-image'})[0].get('src'))\n",
    "# print(first.find_all('img', attrs={'class': 's-image'})[0].get('srcset')) other image sizes for that img\n",
    "\n",
    "# item_price\n",
    "print(first.find_all('span', attrs={'class': 'a-offscreen'})[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: use options instead of chrome_options\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument('--incognito')\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "browserdriver = webdriver.Chrome('chromedriver',chrome_options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "browserdriver.get(URL)\n",
    "content = browserdriver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html class=\"a-no-js\" lang=\"en-us\"><!--<![endif]--><head>\n",
       "<meta content=\"text/html; charset=utf-8\" http-equiv=\"content-type\"/>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"IE=edge,chrome=1\" http-equiv=\"X-UA-Compatible\"/>\n",
       "<title dir=\"ltr\">Robot Check</title>\n",
       "<meta content=\"width=device-width\" name=\"viewport\"/>\n",
       "<link href=\"https://images-na.ssl-images-amazon.com/images/G/01/AUIClients/AmazonUI-3c913031596ca78a3768f4e934b1cc02ce238101.secure.min._V1_.css\" rel=\"stylesheet\"/>\n",
       "<script>\n",
       "\n",
       "if (true === true) {\n",
       "    var ue_t0 = (+ new Date()),\n",
       "        ue_csm = window,\n",
       "        ue = { t0: ue_t0, d: function() { return (+new Date() - ue_t0); } },\n",
       "        ue_furl = \"fls-na.amazon.com\",\n",
       "        ue_mid = \"ATVPDKIKX0DER\",\n",
       "        ue_sid = (document.cookie.match(/session-id=([0-9-]+)/) || [])[1],\n",
       "        ue_sn = \"opfcaptcha.amazon.com\",\n",
       "        ue_id = 'B0NJEBNXVR1BJJVJXAZX';\n",
       "}\n",
       "</script>\n",
       "<script src=\"https://images-na.ssl-images-amazon.com/images/G/01/csminstrumentation/csm-captcha-instrumentation.min.js\"></script><script src=\"https://images-na.ssl-images-amazon.com/images/G/01/csminstrumentation/rd-script-6d68177fa6061598e9509dc4b5bdd08d.js\"></script><script src=\"https://images-na.ssl-images-amazon.com/images/G/01/csminstrumentation/ue-base-1c399ad9886cab69575e1e5ee15c61a1._V313498596_.js\"></script><script src=\"https://images-na.ssl-images-amazon.com/images/G/01/AUIClients/ClientSideMetricsAUIJavascript-51171fbdd28e1a7a61e922e8f0272af8bc74d37b.secure.variant-desktop-session-snapshot-keypress.min._V2_.js\"></script></head>\n",
       "<body>\n",
       "<!--\n",
       "        To discuss automated access to Amazon data please contact api-services-support@amazon.com.\n",
       "        For information about migrating to our APIs refer to our Marketplace APIs at https://developer.amazonservices.com/ref=rm_c_sv, or our Product Advertising API at https://affiliate-program.amazon.com/gp/advertising/api/detail/main.html/ref=rm_c_ac for advertising use cases.\n",
       "-->\n",
       "<!--\n",
       "Correios.DoNotSend\n",
       "-->\n",
       "<div class=\"a-container a-padding-double-large\" style=\"min-width:350px;padding:44px 0 !important\">\n",
       "<div class=\"a-row a-spacing-double-large\" style=\"width: 350px; margin: 0 auto\">\n",
       "<div class=\"a-row a-spacing-medium a-text-center\"><i class=\"a-icon a-logo\"></i></div>\n",
       "<div class=\"a-box a-alert a-alert-info a-spacing-base\">\n",
       "<div class=\"a-box-inner\">\n",
       "<i class=\"a-icon a-icon-alert\"></i>\n",
       "<h4>Enter the characters you see below</h4>\n",
       "<p class=\"a-last\">Sorry, we just need to make sure you're not a robot. For best results, please make sure your browser is accepting cookies.</p>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"a-section\">\n",
       "<div class=\"a-box a-color-offset-background\">\n",
       "<div class=\"a-box-inner a-padding-extra-large\">\n",
       "<form action=\"/errors/validateCaptcha\" method=\"get\" name=\"\">\n",
       "<input name=\"amzn\" type=\"hidden\" value=\"MCrXQl/VvyQcweu/MHZY6g==\"/><input name=\"amzn-r\" type=\"hidden\" value=\"/s?rh=n%3A7141123011%2Cn%3A7147441011%2Cn%3A1040658%2Cn%3A1044442&amp;page=2&amp;qid=1598257670&amp;ref=lp_1044442_pg_2\"/>\n",
       "<div class=\"a-row a-spacing-large\">\n",
       "<div class=\"a-box\">\n",
       "<div class=\"a-box-inner\">\n",
       "<h4>Type the characters you see in this image:</h4>\n",
       "<div class=\"a-row a-text-center\">\n",
       "<img src=\"https://images-na.ssl-images-amazon.com/captcha/kwizfixk/Captcha_obwvkqdfji.jpg\"/>\n",
       "</div>\n",
       "<div class=\"a-row a-spacing-base\">\n",
       "<div class=\"a-row\">\n",
       "<div class=\"a-column a-span6\">\n",
       "</div>\n",
       "<div class=\"a-column a-span6 a-span-last a-text-right\">\n",
       "<a onclick=\"window.location.reload()\">Try different image</a>\n",
       "</div>\n",
       "</div>\n",
       "<input autocapitalize=\"off\" autocomplete=\"off\" autocorrect=\"off\" class=\"a-span12\" id=\"captchacharacters\" name=\"field-keywords\" placeholder=\"Type characters\" spellcheck=\"false\" type=\"text\"/>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"a-section a-spacing-extra-large\">\n",
       "<div class=\"a-row\">\n",
       "<span class=\"a-button a-button-primary a-span12\">\n",
       "<span class=\"a-button-inner\">\n",
       "<button class=\"a-button-text\" type=\"submit\">Continue shopping</button>\n",
       "</span>\n",
       "</span>\n",
       "</div>\n",
       "</div>\n",
       "</form>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"a-divider a-divider-section\"><div class=\"a-divider-inner\"></div></div>\n",
       "<div class=\"a-text-center a-spacing-small a-size-mini\">\n",
       "<a href=\"https://www.amazon.com/gp/help/customer/display.html/ref=footer_cou?ie=UTF8&amp;nodeId=508088\">Conditions of Use</a>\n",
       "<span class=\"a-letter-space\"></span>\n",
       "<span class=\"a-letter-space\"></span>\n",
       "<span class=\"a-letter-space\"></span>\n",
       "<span class=\"a-letter-space\"></span>\n",
       "<a href=\"https://www.amazon.com/gp/help/customer/display.html/ref=footer_privacy?ie=UTF8&amp;nodeId=468496\">Privacy Policy</a>\n",
       "</div>\n",
       "<div class=\"a-text-center a-size-mini a-color-secondary\">\n",
       "          © 1996-2014, Amazon.com, Inc. or its affiliates\n",
       "          <script>\n",
       "           if (true === true) {\n",
       "             document.write('<img src=\"https://fls-na.amaz'+'on.com/'+'1/oc-csi/1/OP/requestId=B0NJEBNXVR1BJJVJXAZX&js=1\" />');\n",
       "           };\n",
       "          </script><img src=\"https://fls-na.amazon.com/1/oc-csi/1/OP/requestId=B0NJEBNXVR1BJJVJXAZX&amp;js=1\"/>\n",
       "<noscript>\n",
       "<img src=\"https://fls-na.amazon.com/1/oc-csi/1/OP/requestId=B0NJEBNXVR1BJJVJXAZX&amp;js=0\">\n",
       "</img></noscript>\n",
       "</div>\n",
       "</div>\n",
       "<script>\n",
       "    if (true === true) {\n",
       "        var head = document.getElementsByTagName('head')[0],\n",
       "            prefix = \"https://images-na.ssl-images-amazon.com/images/G/01/csminstrumentation/\",\n",
       "            elem = document.createElement(\"script\");\n",
       "        elem.src = prefix + \"csm-captcha-instrumentation.min.js\";\n",
       "        head.appendChild(elem);\n",
       "\n",
       "        elem = document.createElement(\"script\");\n",
       "        elem.src = prefix + \"rd-script-6d68177fa6061598e9509dc4b5bdd08d.js\";\n",
       "        head.appendChild(elem);\n",
       "    }\n",
       "    </script>\n",
       "</body></html>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = soup.find_all('div', attrs={'class': 'sg-col-inner'}) #pg2\n",
    "# container = soup.find_all('span', {'class': 'nav-line-1'}) #pg2\n",
    "\n",
    "# container = soup.find_all('div', attrs={'class': 'a-section a-spacing-medium'}) #pg2\n",
    "\n",
    "# container = soup.find_all('div', attrs={'class': 's-item-container'}) #pg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Men's Long Sleeve Crew Neck Triumph Sweater\n",
      "https://m.media-amazon.com/images/I/91PF-WfY-OL._AC_UL320_.jpg\n",
      "$69.98\n"
     ]
    }
   ],
   "source": [
    "first = container[2]\n",
    "# Item_name\n",
    "print(first.find_all('span', attrs={'class': 'a-size-base-plus a-color-base a-text-normal'})[0].text)\n",
    "# item_img_link\n",
    "print(first.find_all('img', attrs={'class': 's-image'})[0].get('src'))\n",
    "# print(first.find_all('img', attrs={'class': 's-image'})[0].get('srcset')) other image sizes for that img\n",
    "\n",
    "# item_price\n",
    "print(first.find_all('span', attrs={'class': 'a-offscreen'})[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AmazonScraper():\n",
    "#     item_names, img_links, prices = [], [], []\n",
    "# #     item_listys = []\n",
    "#     container_items = None\n",
    "#     \"Scrape amazon starting from page 2 to get image_links, item_name and item_price\"\n",
    "#     def __init__(self,urls: list, csv_dir=HOME_DIR):\n",
    "#         self.csv_dir = csv_dir\n",
    "#         self.urls = urls\n",
    "#         self.soup = None\n",
    "#         self.item_names, self.img_links, self.prices = [], [], []\n",
    "        \n",
    "#         self.options = webdriver.ChromeOptions()\n",
    "# #         self.options.add_argument('--incognito')\n",
    "#         self.options.add_argument('--headless')\n",
    "#         self.options.add_argument('--no-sandbox')\n",
    "#         self.options.add_argument('--disable-dev-shm-usage')\n",
    "#         self.options.add_argument(\"--disable-plugins-discovery\");\n",
    "#         self.options.add_argument(\"--start-maximized\")\n",
    "#         self.ua = UserAgent()\n",
    "# #         self.browserdriver = webdriver.Chrome('chromedriver',chrome_options=options)\n",
    "# #         print(self.browserdriver.execute_script(\"return navigator.userAgent;\"))\n",
    "# #         self.browserdriver.delete_all_cookies()\n",
    "        \n",
    "        \n",
    "#     def make_request(self, url):\n",
    "#         browserdriver = webdriver.Chrome('chromedriver',options=self.options)\n",
    "#         if random.random() > 0.25:\n",
    "#             browserdriver.execute_cdp_cmd('Network.setUserAgentOverride', {\"userAgent\": str(self.ua.random)})\n",
    "#         print(browserdriver.execute_script(\"return navigator.userAgent;\"))\n",
    "#         browserdriver.delete_all_cookies()\n",
    "#         browserdriver.get(url)\n",
    "#         content = browserdriver.page_source\n",
    "# #         print(content)\n",
    "#         return content\n",
    "    \n",
    "#     def get_soup(self, url):\n",
    "# #         print(url)\n",
    "#         content = self.make_request(url)\n",
    "# #         print(content)\n",
    "#         return BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "#     def get_container(self, urls, idx=2):\n",
    "#         for url in urls:\n",
    "#             print(url)\n",
    "#             container_items = []\n",
    "#             soup = self.get_soup(url)\n",
    "#     #         print(soup)\n",
    "#             i = 0\n",
    "#             for i in range(3):\n",
    "#                 i += 1                  \n",
    "#                 items = soup.find_all('div', attrs={'class': 'sg-col-inner'})\n",
    "#                 print(i)\n",
    "#     #             print(items)\n",
    "#                 if items != []:\n",
    "# #                     self.container_items = items[idx]\n",
    "#                     container_items = items[idx]\n",
    "#                     return container_items\n",
    "#                     break\n",
    "                \n",
    "#                 soup = self.get_soup(url)\n",
    "#                 time.sleep(5)\n",
    "\n",
    "#             if container_items == []:\n",
    "#                 raise Exception('get_container method failed')\n",
    "        \n",
    "#     def grab_item(self, tag, class_, is_img=False):\n",
    "#         if not isinstance(tag, str): str(tag)        \n",
    "#         if not isinstance(class_, str): str(class_)\n",
    "#         if not isinstance(self.urls, list): list(self.urls)\n",
    "\n",
    "#         container_items = self.get_container(urls=self.urls)\n",
    "        \n",
    "#         item_listys = []\n",
    "#         for i in range(5):\n",
    "#             item_list = container_items.find_all(tag, attrs={'class': class_})\n",
    "#             if item_list != []: \n",
    "#                 item_listys.extend(item_list)\n",
    "#                 break\n",
    "#             container_items = self.get_container(urls=self.urls)\n",
    "# #             print(item_list)\n",
    "#             time.sleep(5)\n",
    "#         if item_list == []: raise Exception('grab item method failed')\n",
    "            \n",
    "#         if is_img:\n",
    "#             item = item_list[0].get('src')\n",
    "#         else:\n",
    "#             item = item_list[0].text\n",
    "            \n",
    "#         return item_listys, item\n",
    "          \n",
    "#     def grab_items(self):\n",
    "#         item_names, img_links, prices = [], [], []\n",
    "        \n",
    "#         #item_name\n",
    "#         item_lists, _ = self.grab_item('span', 'a-size-base-plus a-color-base a-text-normal')\n",
    "#         item_names.extend([i.text for i in item_lists])\n",
    "        \n",
    "#         time.sleep(5)\n",
    "        \n",
    "#         #img_links\n",
    "#         item_lists, _ = self.grab_item('img', 's-image')\n",
    "#         print(f\"lenght: {len([i.get('src') for i in item_lists])}\")\n",
    "#         img_links.extend([i.get('src') for i in item_lists])\n",
    "        \n",
    "#         time.sleep(5)\n",
    "        \n",
    "#         #prices\n",
    "#         item_lists, _ = self.grab_item('span', 'a-offscreen')\n",
    "#         prices.extend([i.text for i in item_lists])\n",
    "        \n",
    "#         time.sleep(5)\n",
    "#         return item_names, img_links, prices\n",
    "        \n",
    "# #     def loop_pages(self):\n",
    "# # #         for i, url in enumerate(self.urls):\n",
    "        \n",
    "# # #             self.get_soup(str(url))\n",
    "# # #             self.get_container(url)\n",
    "# #         self.grab_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonScraper():\n",
    "    \"Scrape amazon starting from page 2 to get image_links, item_name and item_price\"\n",
    "    def __init__(self,urls: list, csv_name):\n",
    "        from tqdm import tqdm\n",
    "        self.CSV_NAME = csv_name\n",
    "        self.urls = urls\n",
    "        self.soup = None\n",
    "        self.item_names, self.img_links, self.prices = [], [], []\n",
    "        \n",
    "        self.options = webdriver.ChromeOptions()\n",
    "#         self.options.add_argument('--incognito')\n",
    "        self.options.add_argument('--headless')\n",
    "        self.options.add_argument('--no-sandbox')\n",
    "        self.options.add_argument('--disable-dev-shm-usage')\n",
    "        self.options.add_argument(\"--disable-plugins-discovery\");\n",
    "#         self.options.add_argument(\"--start-maximized\")\n",
    "        self.ua = UserAgent()\n",
    "        \n",
    "    def make_request(self, url):\n",
    "        browserdriver = webdriver.Chrome('chromedriver',options=self.options)\n",
    "#         if random.random() > 0.25:\n",
    "#         browserdriver.execute_cdp_cmd('Network.setUserAgentOverride', {\"userAgent\": str(self.ua.random)})        \n",
    "        browserdriver.execute_cdp_cmd('Network.setUserAgentOverride', {\"userAgent\": str(generate_user_agent(os=('mac', 'linux')))})\n",
    "\n",
    "#         print(browserdriver.execute_script(\"return navigator.userAgent;\"))\n",
    "        browserdriver.delete_all_cookies()\n",
    "        browserdriver.get(url)\n",
    "        content = browserdriver.page_source\n",
    "#         print(content)\n",
    "        browserdriver.quit()\n",
    "        return content\n",
    "    \n",
    "    def get_soup(self, url):\n",
    "#         print(url)\n",
    "        content = self.make_request(url)\n",
    "#         print(content)\n",
    "        return BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    def get_container(self, url, idx=2):\n",
    "        container_items = []\n",
    "        soup = self.get_soup(url)\n",
    "#         print(soup)\n",
    "        i = 0\n",
    "        for i in range(10):\n",
    "            i += 1                  \n",
    "            items = soup.find_all('div', attrs={'class': 's-latency-cf-section'})\n",
    "#             print(i)\n",
    "            if items != []:\n",
    "                container_items = items\n",
    "                return container_items\n",
    "                break\n",
    "\n",
    "            soup = self.get_soup(url)\n",
    "            time.sleep(5)\n",
    "\n",
    "        if container_items == []:\n",
    "            raise Exception('get_container method failed')\n",
    "        \n",
    "    def grab_item(self, url, tag, class_):\n",
    "        if not isinstance(tag, str): tag = str(tag)        \n",
    "        if not isinstance(class_, str): class_ = str(class_)\n",
    "        \n",
    "        container_items = self.get_container(url=url)\n",
    "\n",
    "        return container_items\n",
    "          \n",
    "    def grab_items(self):        \n",
    "        if not isinstance(self.urls, list): self.urls = list(self.urls)\n",
    "        \n",
    "        product_links, item_names, img_links, prices = [], [], [], []\n",
    "        \n",
    "        for url in tqdm(self.urls, total=len(self.urls)):\n",
    "            \n",
    "            item_lists = self.grab_item(url, None, None)\n",
    "            for it in item_lists:\n",
    "                try:\n",
    "                    names = it.find('span', 'a-size-base-plus a-color-base a-text-normal').text\n",
    "                    time.sleep(4)\n",
    "                    links = it.find('img', 's-image').get('src')\n",
    "                    time.sleep(6)\n",
    "                    prod_links = it.find('img', 's-image').get('src')\n",
    "                    time.sleep(4)\n",
    "                    price_ = it.find('span', 'a-offscreen').text\n",
    "                except AttributeError:\n",
    "                    names = None\n",
    "                    links = None\n",
    "                    price_ = None\n",
    "                product_links.append(prod_links)\n",
    "                item_names.append(names)\n",
    "                img_links.append(links)\n",
    "                prices.append(price_)\n",
    "                \n",
    "        self.get_csv(product_links, item_names, img_links, prices)\n",
    "        \n",
    "        return product_links, item_names, img_links, prices\n",
    "    \n",
    "    def get_csv(self, item_names, img_links, prices):\n",
    "        df = pd.DataFrame({'product_links': product_links,\n",
    "                           'item_names': item_names,\n",
    "                           'img_links': img_links,\n",
    "                           'prices': prices})\n",
    "        df.to_csv(os.path.join(os.getcwd(), str(self.CSV_NAME)), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.system('pip install user_agent http-request-randomizer')\n",
    "os.system('pip install http-request-randomizer')\n",
    "# from user_agent import generate_user_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-25 09:49:46,233 root   DEBUG    === Initialized Proxy Parsers ===\n",
      "2020-08-25 09:49:46,235 root   DEBUG    \t FreeProxy parser of 'http://free-proxy-list.net' with required bandwidth: '150' KBs\n",
      "2020-08-25 09:49:46,236 root   DEBUG    \t PremProxy parser of 'https://premproxy.com/list/' with required bandwidth: '150' KBs\n",
      "2020-08-25 09:49:46,237 root   DEBUG    =================================\n",
      "2020-08-25 09:49:46,538 root   DEBUG    Added 300 proxies from FreeProxy\n",
      "2020-08-25 09:49:47,627 http_request_randomizer.requests.parsers.PremProxyParser DEBUG    Pages: {'', '02.htm', '04.htm', '05.htm', '03.htm'}\n",
      "2020-08-25 09:49:48,706 http_request_randomizer.requests.parsers.js.UnPacker INFO     JS UnPacker init path: https://premproxy.com/js/e2242.js\n",
      "2020-08-25 09:49:49,758 http_request_randomizer.requests.parsers.js.UnPacker DEBUG    portmap: {'r3bd6': '8080', 'r7ea3': '32108', 'r645b': '57856', 'rab5f': '23500', 'r7179': '999', 'r856e': '59010', 'r3bfc': '80', 'r50ad': '37740', 'r2628': '3128', 'rf8e2': '32231', 'r9110': '60020', 'rfcbf': '57797', 'r68b7': '32378', 'rd06b': '59152', 'r757c': '50759', 'r863b': '53281', 'r230c': '45521', 'rc93a': '65205', 'r0eb8': '55667', 'r597e': '55078', 'rd7da': '5836', 'rce4f': '58249', 'rd130': '8000', 'r23c1': '52590', 'r811d': '8888', 'r0219': '40894', 'ra20c': '39371', 'rffa0': '32842', 'r44c5': '3129', 'r56de': '44410', 'r0517': '44612', 'rce5d': '47096', 'r77df': '8118', 'r0dda': '6000', 'r5e1f': '3163', 're993': '40575', 'r27e2': '3838', 'r062e': '53410', 'r8913': '33010', 'r8900': '15027', 'r2f02': '47470', 'r3682': '82', 'rfe3d': '51011', 'r3936': '43031', 'r1986': '25834', 'r562d': '56379', 'r01b8': '37717', 'r4b45': '42535', 'rb6c7': '49480', 'r820b': '43313', 'r5913': '53758', 'r0dcf': '49049', 'r6d88': '1234', 'rc562': '8082', 'r30de': '9999', 'rb82a': '8090', 'rfce7': '8081', 'reb06': '30677', 'r1916': '43871', 'r61f1': '45282', 'rde28': '8291', 'r94ac': '54555', 're006': '47236', 'rcc28': '55357', 'r087e': '43922', 'r0f18': '47744', 'r3675': '43895', 'r96ad': '38002', 'r0882': '49044', 'r10cc': '9991', 'r1aed': '41731', 'r4f4f': '45673', 'r14cf': '32412', 're287': '54547', 'rd8ae': '61323', 'r8572': '35953', 'r5b62': '42461', 'rd927': '30280', 'rcb35': '61711', 'r3d8b': '1080', 'r7baf': '61018', 'r59b1': '33855', 'r57bc': '34638', 'r3a8f': '61378', 'rac2c': '44805'}\n",
      "2020-08-25 09:49:55,242 root   DEBUG    Added 264 proxies from PremProxy\n",
      "2020-08-25 09:49:55,247 root   DEBUG    Total proxies = 564\n",
      "2020-08-25 09:49:55,251 root   DEBUG    Filtered proxies = 564\n"
     ]
    }
   ],
   "source": [
    "from http_request_randomizer.requests.proxy.requestProxy import RequestProxy\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "# start = time.time()\n",
    "req_proxy = RequestProxy();\n",
    "#     print(\"Initialization took: {0} sec\".format((time.time() - start)))\n",
    "#     print(\"Size: {0}\".format(len(req_proxy.get_proxy_list())))\n",
    "#     print(\"ALL = {0} \".format(list(map(lambda x: x.get_address(), req_proxy.get_proxy_list()))))\n",
    "\n",
    "#     test_url = 'http://ipv4.icanhazip.com'\n",
    "\n",
    "#     while True:\n",
    "#         start = time.time()\n",
    "#         request = req_proxy.generate_proxied_request(test_url)\n",
    "#         print(\"Proxied Request Took: {0} sec => Status: {1}\".format((time.time() - start), request.__str__()))\n",
    "#         if request is not None:\n",
    "#             print(\"\\t Response: ip={0}\".format(u''.join(request.text).encode('utf-8')))\n",
    "#         print(\"Proxy List Size: {0}\".format(len(req_proxy.get_proxy_list())))\n",
    "\n",
    "#         print(\"-> Going to sleep..\")\n",
    "#         time.sleep(10)\n",
    "#         break\n",
    "\n",
    "all_proxies = req_proxy.get_proxy_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'45.123.42.149:37740'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_proxies[0].get_address()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies_that_work_us['206.127.88.18:80', '54.214.52.181']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used to test proxies\n",
    "\n",
    "# from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "\n",
    "# # pxy = '206.127.88.18:80'\n",
    "# pxy = '54.214.52.181'\n",
    "# prox = Proxy()\n",
    "\n",
    "# prox.proxy_type = ProxyType.MANUAL\n",
    "# prox.http_proxy = pxy\n",
    "\n",
    "# prox.ssl_proxy = pxy\n",
    "\n",
    "# capabilities = webdriver.DesiredCapabilities.CHROME\n",
    "# prox.add_to_capabilities(capabilities)\n",
    "\n",
    "# options = webdriver.ChromeOptions()\n",
    "# options.add_argument('log-level=3')\n",
    "# options.add_argument('--headless')\n",
    "# options.add_argument('--no-sandbox')\n",
    "# options.add_argument('--disable-dev-shm-usage')\n",
    "# options.add_argument(\"--disable-plugins-discovery\")\n",
    "# driver = webdriver.Chrome(options=options, desired_capabilities=capabilities)\n",
    "# # driver.get('https://www.google.com/')\n",
    "# driver.get(URL_[0])\n",
    "# content = driver.page_source\n",
    "        \n",
    "# ele = driver.find_element(By.CSS_SELECTOR, 'html')\n",
    "\n",
    "# #         Returns and base64 encoded string into image\n",
    "# ele.screenshot('./image.png')\n",
    "\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonScraper():\n",
    "    \"Scrape amazon starting from page 2 to get image_links, item_name and item_price\"\n",
    "    def __init__(self,urls: list, csv_name):\n",
    "        self.CSV_NAME = csv_name\n",
    "        self.urls = urls\n",
    "        self.soup = None\n",
    "        self.item_names, self.img_links, self.prices = [], [], []\n",
    "        \n",
    "        self.options = webdriver.ChromeOptions()\n",
    "#         self.options.add_argument('--incognito')\n",
    "        self.options.add_argument('--headless')\n",
    "        self.options.add_argument('--no-sandbox')\n",
    "        self.options.add_argument('--disable-dev-shm-usage')\n",
    "        self.options.add_argument(\"--disable-plugins-discovery\")\n",
    "#         self.options.add_argument(\"--start-maximized\")\n",
    "        self.ua = UserAgent()\n",
    "        self.proxies = ['206.127.88.18:80', '54.214.52.181']\n",
    "        \n",
    "    def make_request(self, url, change_default=False):\n",
    "        if not change_default:\n",
    "            browserdriver = webdriver.Chrome('chromedriver',options=self.options)\n",
    "        else:\n",
    "#             https://gist.github.com/tushortz/cba8b25f9d80f584f807b65890f37be5\n",
    "            PROXY = random.sample(self.proxies, 1)[0]\n",
    "            capabilities = webdriver.DesiredCapabilities.CHROME['proxy'] = {\n",
    "                \"httpProxy\": PROXY,\n",
    "                \"ftpProxy\": PROXY,\n",
    "                \"sslProxy\": PROXY,\n",
    "                \"proxyType\": \"MANUAL\",\n",
    "\n",
    "            }\n",
    "            browserdriver = webdriver.Chrome('chromedriver',options=self.options, desired_capabilities=capabilities, port=80)\n",
    "#         if random.random() > 0.25:\n",
    "\n",
    "        browserdriver.execute_cdp_cmd('Network.setUserAgentOverride', {\"userAgent\": str(self.ua.random)})\n",
    "#         print(browserdriver.execute_script(\"return navigator.userAgent;\"))\n",
    "        browserdriver.delete_all_cookies()\n",
    "        browserdriver.get(url)\n",
    "        content = browserdriver.page_source\n",
    "        \n",
    "        ele = browserdriver.find_element(By.CSS_SELECTOR, 'html')\n",
    "\n",
    "#         Returns and base64 encoded string into image\n",
    "        ele.screenshot('./image.png')\n",
    "        \n",
    "#         print(content)\n",
    "        browserdriver.quit()\n",
    "        return content\n",
    "    \n",
    "    def get_soup(self, url, change_default):\n",
    "#         print(url)\n",
    "        content = self.make_request(url, change_default)\n",
    "#         print(content)\n",
    "        return BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    def get_container(self, url, idx=2):\n",
    "        container_items = []\n",
    "        time.sleep(random.randint(10, 35))\n",
    "        soup = self.get_soup(url, change_default=False)\n",
    "#         print(soup)\n",
    "        i = 0\n",
    "        for i in range(15):\n",
    "            i += 1                  \n",
    "            items = soup.find_all('div', attrs={'class': 's-latency-cf-section'})\n",
    "            if items != []:\n",
    "                container_items = items\n",
    "                return container_items\n",
    "                break\n",
    "            \n",
    "#             time.sleep(random.randint(10, 25))\n",
    "            soup = self.get_soup(url, change_default=True)\n",
    "\n",
    "        if container_items == []:\n",
    "            raise Exception('get_container method failed')\n",
    "        \n",
    "    def grab_item(self, url, tag, class_):\n",
    "        if not isinstance(tag, str): tag = str(tag)        \n",
    "        if not isinstance(class_, str): class_ = str(class_)\n",
    "        \n",
    "        container_items = self.get_container(url=url)\n",
    "\n",
    "        return container_items\n",
    "          \n",
    "    def grab_items(self):        \n",
    "        if not isinstance(self.urls, list): self.urls = list(self.urls)\n",
    "        \n",
    "        product_links, item_names, img_links, prices = [], [], [], []\n",
    "        \n",
    "        df_ = pd.DataFrame(columns= ['product_links', 'item_names', 'img_links', 'prices'])\n",
    "        \n",
    "        for i, url in enumerate(tqdm(self.urls, total=len(self.urls))):\n",
    "            \n",
    "            item_lists = self.grab_item(url, None, None)\n",
    "            for it in item_lists:\n",
    "                try:\n",
    "                    names = it.find('span', 'a-size-base-plus a-color-base a-text-normal').text\n",
    "#                     time.sleep(10)\n",
    "                    links = it.find('img', 's-image').get('src')\n",
    "#                     time.sleep(10)\n",
    "                    prod_links = 'https://www.amazon.com' + str(it.find('a', 'a-link-normal s-no-outline').get('href'))\n",
    "#                     time.sleep(5)\n",
    "                    price_ = it.find('span', 'a-offscreen').text\n",
    "                except AttributeError:\n",
    "                    names = None\n",
    "                    links = None\n",
    "                    price_ = None\n",
    "                product_links.append(prod_links)\n",
    "                item_names.append(names)\n",
    "                img_links.append(links)\n",
    "                prices.append(price_)\n",
    "                \n",
    "#                 save a df every entry\n",
    "#                 if i % 1 == 0:\n",
    "                df_.loc[len(df_)] = [prod_links, names, links, price_]\n",
    "                df_.to_csv(os.path.join(os.getcwd(), str(self.CSV_NAME) + '_sub.csv'), index=None)\n",
    "        \n",
    "        self.get_csv(product_links, item_names, img_links, prices)\n",
    "        \n",
    "#         remove the sub if you go through the full url list\n",
    "#         os.remove(str(os.path.join(os.getcwd(), str(self.CSV_NAME) + '_sub.csv')))\n",
    "        \n",
    "        return product_links, item_names, img_links, prices\n",
    "    \n",
    "    def get_csv(self, product_links, item_names, img_links, prices):\n",
    "        df = pd.DataFrame({'product_links': product_links,\n",
    "                           'item_names': item_names,\n",
    "                           'img_links': img_links,\n",
    "                           'prices': prices})\n",
    "        df.to_csv(os.path.join(os.getcwd(), str(self.CSV_NAME) + '.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 1/2 [00:36<00:36, 36.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 2/2 [01:04<00:00, 32.03s/it]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "csv_name = 'Test'\n",
    "URL_ = [f'https://www.amazon.com/s?rh=n%3A7141123011%2Cn%3A7147441011%2Cn%3A1040658%2Cn%3A2476517011&page={i}&qid=1598342505&ref=lp_2476517011_pg_{i}' for i in range (2,4)]\n",
    "a = AmazonScraper(URL_, csv_name=csv_name)\n",
    "product_links, item_names, img_links, prices = a.grab_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_links</th>\n",
       "      <th>item_names</th>\n",
       "      <th>img_links</th>\n",
       "      <th>prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.amazon.com/dp/B07Z5CJLFJ/ref=sr_1_...</td>\n",
       "      <td>Trim Fit Party Polo, Bright White</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71kIOVmfK5...</td>\n",
       "      <td>$77.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.amazon.com/28-Palms-Standard-Fit-T...</td>\n",
       "      <td>Amazon Brand - 28 Palms Men's Standard-Fit Tro...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A13Ysvj37j...</td>\n",
       "      <td>$20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.amazon.com/Hanes-Sleeve-Pocket-Bee...</td>\n",
       "      <td>Men's 2 Pack Short-Sleeve Pocket Beefy-T</td>\n",
       "      <td>https://m.media-amazon.com/images/I/713VPdTx06...</td>\n",
       "      <td>$10.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.amazon.com/Comfort-Colors-Adult-Sl...</td>\n",
       "      <td>Men's Adult Short Sleeve Tee, Style 1717</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61jgR5y0ib...</td>\n",
       "      <td>$9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.amazon.com/Wrangler-Authentics-Sle...</td>\n",
       "      <td>Authentics Men's Short Sleeve Classic Woven Shirt</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1JsWvuVlh...</td>\n",
       "      <td>$17.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>https://www.amazon.com/Robert-Graham-Julia-Wov...</td>\n",
       "      <td>Julia Woven Shirt Classic Fit</td>\n",
       "      <td>https://m.media-amazon.com/images/I/91racEocpc...</td>\n",
       "      <td>$118.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>https://www.amazon.com/28-Palms-Relaxed-Fit-Tr...</td>\n",
       "      <td>Amazon Brand - 28 Palms Men's Relaxed-Fit Silk...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/91TkFXdpaI...</td>\n",
       "      <td>$36.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>https://www.amazon.com/Glock-OEM-Perfection-T-...</td>\n",
       "      <td>Men's Perfection T-Shirt Short Sleeve Cotton</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81e7Jht4Aj...</td>\n",
       "      <td>$13.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>https://www.amazon.com/Green-10102943-camiseta...</td>\n",
       "      <td>Men's Paddy Polo Shirt</td>\n",
       "      <td>https://m.media-amazon.com/images/I/912cpVkXno...</td>\n",
       "      <td>$63.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>https://www.amazon.com/Zengjo-Spandex-Crewneck...</td>\n",
       "      <td>Men's Casual Cotton Spandex Striped Crewneck L...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71RM8K34u5...</td>\n",
       "      <td>$19.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_links  ...   prices\n",
       "0   https://www.amazon.com/dp/B07Z5CJLFJ/ref=sr_1_...  ...   $77.99\n",
       "1   https://www.amazon.com/28-Palms-Standard-Fit-T...  ...   $20.00\n",
       "2   https://www.amazon.com/Hanes-Sleeve-Pocket-Bee...  ...   $10.50\n",
       "3   https://www.amazon.com/Comfort-Colors-Adult-Sl...  ...    $9.99\n",
       "4   https://www.amazon.com/Wrangler-Authentics-Sle...  ...   $17.99\n",
       "..                                                ...  ...      ...\n",
       "91  https://www.amazon.com/Robert-Graham-Julia-Wov...  ...  $118.50\n",
       "92  https://www.amazon.com/28-Palms-Relaxed-Fit-Tr...  ...   $36.45\n",
       "93  https://www.amazon.com/Glock-OEM-Perfection-T-...  ...   $13.49\n",
       "94  https://www.amazon.com/Green-10102943-camiseta...  ...   $63.01\n",
       "95  https://www.amazon.com/Zengjo-Spandex-Crewneck...  ...   $19.98\n",
       "\n",
       "[96 rows x 4 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.read_csv(str(csv_name) + '_sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_links</th>\n",
       "      <th>item_names</th>\n",
       "      <th>img_links</th>\n",
       "      <th>prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.amazon.com/dp/B07Z5CJLFJ/ref=sr_1_...</td>\n",
       "      <td>Trim Fit Party Polo, Bright White</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71kIOVmfK5...</td>\n",
       "      <td>$77.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.amazon.com/28-Palms-Standard-Fit-T...</td>\n",
       "      <td>Amazon Brand - 28 Palms Men's Standard-Fit Tro...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A13Ysvj37j...</td>\n",
       "      <td>$20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.amazon.com/Hanes-Sleeve-Pocket-Bee...</td>\n",
       "      <td>Men's 2 Pack Short-Sleeve Pocket Beefy-T</td>\n",
       "      <td>https://m.media-amazon.com/images/I/713VPdTx06...</td>\n",
       "      <td>$10.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.amazon.com/Comfort-Colors-Adult-Sl...</td>\n",
       "      <td>Men's Adult Short Sleeve Tee, Style 1717</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61jgR5y0ib...</td>\n",
       "      <td>$9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.amazon.com/Wrangler-Authentics-Sle...</td>\n",
       "      <td>Authentics Men's Short Sleeve Classic Woven Shirt</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1JsWvuVlh...</td>\n",
       "      <td>$17.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>https://www.amazon.com/Robert-Graham-Julia-Wov...</td>\n",
       "      <td>Julia Woven Shirt Classic Fit</td>\n",
       "      <td>https://m.media-amazon.com/images/I/91racEocpc...</td>\n",
       "      <td>$118.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>https://www.amazon.com/28-Palms-Relaxed-Fit-Tr...</td>\n",
       "      <td>Amazon Brand - 28 Palms Men's Relaxed-Fit Silk...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/91TkFXdpaI...</td>\n",
       "      <td>$36.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>https://www.amazon.com/Glock-OEM-Perfection-T-...</td>\n",
       "      <td>Men's Perfection T-Shirt Short Sleeve Cotton</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81e7Jht4Aj...</td>\n",
       "      <td>$13.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>https://www.amazon.com/Green-10102943-camiseta...</td>\n",
       "      <td>Men's Paddy Polo Shirt</td>\n",
       "      <td>https://m.media-amazon.com/images/I/912cpVkXno...</td>\n",
       "      <td>$63.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>https://www.amazon.com/Zengjo-Spandex-Crewneck...</td>\n",
       "      <td>Men's Casual Cotton Spandex Striped Crewneck L...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71RM8K34u5...</td>\n",
       "      <td>$19.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_links  ...   prices\n",
       "0   https://www.amazon.com/dp/B07Z5CJLFJ/ref=sr_1_...  ...   $77.99\n",
       "1   https://www.amazon.com/28-Palms-Standard-Fit-T...  ...   $20.00\n",
       "2   https://www.amazon.com/Hanes-Sleeve-Pocket-Bee...  ...   $10.50\n",
       "3   https://www.amazon.com/Comfort-Colors-Adult-Sl...  ...    $9.99\n",
       "4   https://www.amazon.com/Wrangler-Authentics-Sle...  ...   $17.99\n",
       "..                                                ...  ...      ...\n",
       "91  https://www.amazon.com/Robert-Graham-Julia-Wov...  ...  $118.50\n",
       "92  https://www.amazon.com/28-Palms-Relaxed-Fit-Tr...  ...   $36.45\n",
       "93  https://www.amazon.com/Glock-OEM-Perfection-T-...  ...   $13.49\n",
       "94  https://www.amazon.com/Green-10102943-camiseta...  ...   $63.01\n",
       "95  https://www.amazon.com/Zengjo-Spandex-Crewneck...  ...   $19.98\n",
       "\n",
       "[96 rows x 4 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.read_csv(str(csv_name) + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Men's Clothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [1:54:17<00:00, 27.43s/it]  \n"
     ]
    }
   ],
   "source": [
    "# csv_name = 'Men Shirts'\n",
    "# URL_ = [f'https://www.amazon.com/s?rh=n%3A7141123011%2Cn%3A7147441011%2Cn%3A1040658%2Cn%3A2476517011&page={i}&qid=1598342505&ref=lp_2476517011_pg_{i}' for i in range (2,252)]\n",
    "# a = AmazonScraper(URL_, csv_name=csv_name)\n",
    "# product_links, item_names, img_links, prices = a.grab_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_links      0\n",
       "item_names       262\n",
       "img_links        262\n",
       "prices           262\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(csv_name).isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done\n",
    "## csv_name = 'Men T-shirts'\n",
    "## URL_ = [f'https://www.amazon.com/s?k=Men%27s+T-Shirts+%26+Tanks&i=fashion-mens-clothing&rh=n%3A15697821011&page={i}&_encoding=UTF8&c=ts&qid=1598342630&ts_id=15697821011&ref=sr_pg{i}' for i in range (2,252)]\n",
    "## a = AmazonScraper(URL_, csv_name=csv_name)\n",
    "## product_links, item_names, img_links, prices = a.grab_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not done\n",
    "# csv_name = 'Men Sweaters'\n",
    "# URL_ = [f'https://www.amazon.com/s?rh=n%3A7141123011%2Cn%3A7147441011%2Cn%3A1040658%2Cn%3A1045684&page={i}&qid=1598342512&ref=lp_1045684_pg_{i}' for i in range (2,52)]\n",
    "# a = AmazonScraper(URL_, csv_name=csv_name)\n",
    "# product_links, item_names, img_links, prices = a.grab_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/Scraper/Men Suits/Blazers_sub.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7eb611f640ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mURL_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf'https://www.amazon.com/s?rh=n%3A7141123011%2Cn%3A7147441011%2Cn%3A1040658%2Cn%3A1044442&page={i}&qid=1598257670&ref=lp_1044442_pg_{i}'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAmazonScraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsv_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mproduct_links\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_links\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrab_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-76f412d6b90e>\u001b[0m in \u001b[0;36mgrab_items\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m#                 if i % 1 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mdf_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprod_links\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprice_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0mdf_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCSV_NAME\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_sub.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_links\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_links\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m         )\n\u001b[0;32m-> 3204\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             )\n\u001b[1;32m    190\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Scraper/Men Suits/Blazers_sub.csv'"
     ]
    }
   ],
   "source": [
    "csv_name = 'Men Suits_Blazers'\n",
    "URL_ = [f'https://www.amazon.com/s?rh=n%3A7141123011%2Cn%3A7147441011%2Cn%3A1040658%2Cn%3A1044442&page={i}&qid=1598257670&ref=lp_1044442_pg_{i}' for i in range (2,55)]\n",
    "a = AmazonScraper(URL_, csv_name=csv_name)\n",
    "product_links, item_names, img_links, prices = a.grab_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = 'Men Jackets_Coats'\n",
    "URL_ = [f'https://www.amazon.com/s?rh=n%3A7141123011%2Cn%3A7147441011%2Cn%3A1040658%2Cn%3A1045830&page={i}&qid=1598342517&ref=lp_1045830_pg_{i}' for i in range (2,252)]\n",
    "a = AmazonScraper(URL_, csv_name=csv_name)\n",
    "product_links, item_names, img_links, prices = a.grab_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = 'Men Hoodies_Sweatshirts'\n",
    "URL_ = [f'https://www.amazon.com/s?k=Men%27s+Fashion+Hoodies+%26+Sweatshirts&i=fashion-mens-clothing&rh=n%3A1258644011&page={i}&_encoding=UTF8&c=ts&qid=1598343036&ts_id=1258644011&ref=sr_pg_{i}' for i in range (2,51)]\n",
    "a = AmazonScraper(URL_, csv_name=csv_name)\n",
    "product_links, item_names, img_links, prices = a.grab_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = 'Men Pants'\n",
    "URL_ = [f'https://www.amazon.com/s?k=Men%27s+Pants&i=fashion-mens-clothing&rh=n%3A1045558&page={i}&_encoding=UTF8&c=ts&qid=1598342526&ts_id=1045558&ref=sr_pg_{i}' for i in range (2,82)]\n",
    "a = AmazonScraper(URL_, csv_name=csv_name)\n",
    "product_links, item_names, img_links, prices = a.grab_items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Women's Clothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [2:18:40<00:00, 33.28s/it]  \n"
     ]
    }
   ],
   "source": [
    "# # done\n",
    "# csv_name = 'Women Dresses'\n",
    "# URL_ = [f'https://www.amazon.com/s?rh=n%3A7141123011%2Cn%3A7147440011%2Cn%3A1040660%2Cn%3A1045024&page={i}&qid=1598343388&ref=lp_1045024_pg_{i}' for i in range (2,252)]\n",
    "# a = AmazonScraper(URL_, csv_name=csv_name)\n",
    "# product_links, item_names, img_links, prices = a.grab_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [2:19:47<00:00, 33.55s/it]  \n"
     ]
    }
   ],
   "source": [
    "# #done\n",
    "# csv_name = 'Women Tops_Tees_Blouses'\n",
    "# URL_ = [f'https://www.amazon.com/s?rh=n%3A7141123011%2Cn%3A7147440011%2Cn%3A1040660%2Cn%3A2368343011&page={i}&qid=1598343484&ref=lp_2368343011_pg_{i}' for i in range (2,252)]\n",
    "# a = AmazonScraper(URL_, csv_name=csv_name)\n",
    "# product_links, item_names, img_links, prices = a.grab_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 67/170 [41:05<1:05:04, 37.91s/it]"
     ]
    }
   ],
   "source": [
    "csv_name = 'Womens Coats_Jackets'\n",
    "URL_ = [f'https://www.amazon.com/s?rh=n%3A7141123011%2Cn%3A7147440011%2Cn%3A1040660%2Cn%3A1044646&page={i}&qid=1598343492&ref=lp_1044646_pg_{i}' for i in range (2,172)]\n",
    "a = AmazonScraper(URL_, csv_name=csv_name)\n",
    "product_links, item_names, img_links, prices = a.grab_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [30:32<00:00, 45.80s/it]\n"
     ]
    }
   ],
   "source": [
    "# # done\n",
    "# csv_name = 'Womens Jumpsuits_Rompers_Overalls'\n",
    "# URL_ = [f'https://www.amazon.com/s?k=Women%27s+Jumpsuits%2C+Rompers+%26+Overalls&i=fashion-womens-clothing&rh=n%3A9522930011&page={i}&_encoding=UTF8&c=ts&qid=1598343498&ts_id=9522930011&ref=sr_pg_{i}' for i in range (2,42)]\n",
    "# a = AmazonScraper(URL_, csv_name=csv_name)\n",
    "# product_links, item_names, img_links, prices = a.grab_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = 'Womens Fashion_Hoodies_Sweatshirts'\n",
    "URL_ = [f'https://www.amazon.com/s?k=Women%27s+Fashion+Hoodies+%26+Sweatshirts&i=fashion-womens-clothing&rh=n%3A1258603011&page={i}&_encoding=UTF8&c=ts&qid=1598343501&ts_id=1258603011&ref=sr_pg_{i}' for i in range (2,52)]\n",
    "a = AmazonScraper(URL_, csv_name=csv_name)\n",
    "product_links, item_names, img_links, prices = a.grab_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = 'Womens Sweaters'\n",
    "URL_ = [f'https://www.amazon.com/s?rh=n%3A7141123011%2Cn%3A7147440011%2Cn%3A1040660%2Cn%3A1044456&page={i}&qid=1598343503&ref=lp_1044456_pg_{i}' for i in range (2,172)]\n",
    "a = AmazonScraper(URL_, csv_name=csv_name)\n",
    "product_links, item_names, img_links, prices = a.grab_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = 'Womens Sandals'\n",
    "URL_ = [f'https://www.amazon.com/s?k=Women%27s+Sandals&i=fashion-womens-shoes&rh=n%3A679425011&page={i}&_encoding=UTF8&c=ts&qid=1598344871&ts_id=679425011&ref=sr_pg_{i}' for i in range (2,172)]\n",
    "a = AmazonScraper(URL_, csv_name=csv_name)\n",
    "product_links, item_names, img_links, prices = a.grab_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [04:07<00:00,  5.16s/it]\n"
     ]
    }
   ],
   "source": [
    "item_names, img_links, prices = a.grab_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_names</th>\n",
       "      <th>img_links</th>\n",
       "      <th>prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Musterbrand Marvel Men Cardigan Captain Americ...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/91w0b-vry2...</td>\n",
       "      <td>$136.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sean John Men's Long Sleeve Pullover Jaquard T...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1rSBVWis3...</td>\n",
       "      <td>$68.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paul Fredrick Men's Supima Mock Neck Sweater</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51wPl3UcJb...</td>\n",
       "      <td>$85.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cutter &amp; Buck Men's Big and Tall B&amp;t Machine W...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81BHJ6zT+o...</td>\n",
       "      <td>$63.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon Brand - Buttoned Down Men's 100% Supima...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/91TZnLOxPE...</td>\n",
       "      <td>$36.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          item_names  ...   prices\n",
       "0  Musterbrand Marvel Men Cardigan Captain Americ...  ...  $136.71\n",
       "1  Sean John Men's Long Sleeve Pullover Jaquard T...  ...   $68.94\n",
       "2       Paul Fredrick Men's Supima Mock Neck Sweater  ...   $85.00\n",
       "3  Cutter & Buck Men's Big and Tall B&t Machine W...  ...   $63.69\n",
       "4  Amazon Brand - Buttoned Down Men's 100% Supima...  ...   $36.63\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(os.getcwd(), csv_name))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2304, 3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_names    93\n",
       "img_links     93\n",
       "prices        93\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_names    IZOD Men's Premium Essentials Solid V-Neck 12 ...\n",
       "img_links     https://m.media-amazon.com/images/I/81iL0gtro8...\n",
       "prices                                                   $21.99\n",
       "Name: 20, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('APRAW Mens Casual Slim Fit Soft Cotton V-Neck Button Down Lightweight Knitted Cardigan Sweater with Shawl Collar',\n",
       " 'https://m.media-amazon.com/images/I/61zqXEHkoDL._AC_UL320_.jpg',\n",
       " '$23.99')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.item_names[21], df.img_links[21], df.prices[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
